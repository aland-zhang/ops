日期：2015/11/10 - 2015/11/11 time 16:15
主机：e01, n33, n34
目的：再探oVirt-测试glusterfs的可用性
操作内容：
一、基础操作
1、资源
ovirt engine: e01
ovirt node: n33, n34

2、hosts
10.50.200.1 e01.test
10.50.200.33 n33.test
10.50.200.34 n34.test
10.50.200.86 n86.test

二、配置主机
以n33为例，安装OS后：
hostname n33.test
vi /etc/sysconfig/network
vi /etc/hosts
curl http://my_office/repo/local-office.repo -o /etc/yum.repos.d/local-office.repo
curl http://my_office/ovirt/ovirt-3.5.repo -o /etc/yum.repos.d/ovirt-3.5.repo
curl http://my_office/ovirt/ovirt-3.6.repo -o /etc/yum.repos.d/ovirt-3.6.repo
mv /etc/yum.repos.d/CentOS-* /tmp/
yum clean all && yum makecache
yum install yum-plugin-priorities -y 
yum install ntp vim lrzsz -y
yum install vdsm vdsm-cli -y



三、测试gluster服务的可用性（2节点）
1、配置存储
1）调整防火墙：
## ovirt LAN
-A INPUT -s 10.50.200.0/24 -j ACCEPT

2）分区
yum install lvm2 xfsprogs -y
如果已经存在/data分区，要先umount然后fdisk删除分区再继续操作
pvcreate /dev/sdb
vgcreate vg0 /dev/sdb 
lvcreate -l 100%FREE -n lv01 vg0
mkfs.xfs -f -i size=512 /dev/vg0/lv01 
mkdir /data
cat <<_EOF >>/etc/fstab
UUID=$(blkid /dev/vg0/lv01 |cut -d'"' -f2) /data                   xfs     defaults        0 0
_EOF
mount -a

3）配置 glusterfs 服务
mkdir /data/ovirt/

yum install glusterfs-server
service glusterd start
chkconfig glusterd on

[root@n33 ~]# gluster peer probe n34.test
[root@n33 ~]# gluster volume create ovirt-data replica 2 transport tcp \
n33.test:/data/ovirt/data \
n34.test:/data/ovirt/data
[root@n33 ~]# gluster volume start ovirt-data
【配置参数】
gluster volume set ovirt-data diagnostics.count-fop-hits on
gluster volume set ovirt-data diagnostics.latency-measurement on
gluster volume set ovirt-data storage.owner-gid 36
gluster volume set ovirt-data storage.owner-uid 36 
gluster volume set ovirt-data cluster.server-quorum-type server
gluster volume set ovirt-data cluster.quorum-type auto
gluster volume set ovirt-data network.remote-dio enable
gluster volume set ovirt-data cluster.eager-lock enable
gluster volume set ovirt-data performance.stat-prefetch off
gluster volume set ovirt-data performance.io-cache off
gluster volume set ovirt-data performance.read-ahead off
gluster volume set ovirt-data performance.quick-read off
gluster volume set ovirt-data auth.allow \*
gluster volume set ovirt-data user.cifs enable
gluster volume set ovirt-data nfs.disable off

2、在 engine 页面选择菜单：“数据中心-Default-存储-新建域”
名称：data
域功能/存储类型：Data/GlusterFS
使用主机：n33.test
路径：n33.test:/ovirt-data
挂载选项：backupvolfile-server=n34.test



四、测试
1、客户机挂载
[root@n86 ~]# mount.glusterfs -o backupvolfile-server=n34.test n33.test:/ovirt-data /data/test

2、测试用例
【测试用例01】断开其中一个节点的网络
1）断开n33的网卡
2）客户机
[root@n86 ~]# ls /data/test
ls: cannot access /data/test: Transport endpoint is not connected
3）ovirt页面的状态
数据中心：无响应
主机：n33 无响应；n34 无响应；
data域：失效
虚拟机：在n33上运行的vm处于未知状态，在n34上运行的vm处于暂停状态
4）恢复
启用网卡后，大约3分钟后，data域恢复工作。


【测试用例02】调整server-quorum-ratio 为 30%
1）设定参数
gluster volume set all cluster.server-quorum-ratio 30%
2）重复 测试用例01
等待几秒后：
[root@n86 ~]# ls /data/test
09cb8372-a68d-47dc-962e-70b5225be6bc  __DIRECT_IO_TEST__
说明，已经切换到备用节点，且通过ss -ant dst :49152可以验证。
[root@n86 test]# touch 1111
touch: cannot touch `1111': Read-only file system
但是，系统是只读的。

3）ovirt页面的状态
数据中心：无响应
主机：n33 无响应； n34 在3分钟后自行恢复
虚拟机：在n33上运行的vm处于未知状态，在n34上运行的vm处于暂停状态
data域：失效
4）恢复
启用网卡后，恢复到默认值：
gluster volume reset all


【测试用例03】调整server-quorum-ratio 为 70%
1）设定参数
gluster volume set ovirt-data cluster.server-quorum-type server
gluster volume set ovirt-data cluster.quorum-type auto
gluster volume set all cluster.server-quorum-ratio 70%
2）重复 测试用例01
现象和 测试用例01 一致

3）恢复
gluster volume reset all
gluster volume reset ovirt-data


【测试用例04】禁用quorum
1）调整集群参数，去掉quorum相关的配置。
gluster volume set ovirt-data diagnostics.count-fop-hits on
gluster volume set ovirt-data diagnostics.latency-measurement on
gluster volume set ovirt-data storage.owner-gid 36
gluster volume set ovirt-data storage.owner-uid 36 
gluster volume set ovirt-data network.remote-dio enable
gluster volume set ovirt-data cluster.eager-lock enable
gluster volume set ovirt-data performance.stat-prefetch off
gluster volume set ovirt-data performance.io-cache off
gluster volume set ovirt-data performance.read-ahead off
gluster volume set ovirt-data performance.quick-read off
gluster volume set ovirt-data auth.allow \*
gluster volume set ovirt-data user.cifs enable
gluster volume set ovirt-data nfs.disable off

2）重复 测试用例01
等待几秒后可以发现，已经切换到备用节点，且通过ss -ant dst :49152可以验证是连接到节点n34上。
[root@n86 ~]# ls /data/test/
09cb8372-a68d-47dc-962e-70b5225be6bc  __DIRECT_IO_TEST__
[root@n86 ~]# cd /data/test/
[root@n86 test]# touch 1111
[root@n86 test]# ls
09cb8372-a68d-47dc-962e-70b5225be6bc  1111  __DIRECT_IO_TEST__
上述说明n33失效后，集群依然可以写入数据。

3）ovirt页面的状态
数据中心：无响应
主机：n33 无响应； n34 正常
data域：有效
虚拟机：在n33上运行的vm处于未知状态无法做任何操作（即无法强行关闭损失内存的数据，然后在其他host上启动这个vm），在n34上运行的vm正常

4）恢复
启用网卡后，n33恢复正常，虚拟机处于暂停状态的异常无法直接启动，通过先关机后再启动后恢复可用。
















