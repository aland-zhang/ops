使用lvm来管理iscsi存储
2016/11/29


目的：测试如何使用 lvm 来操作 iscsi 块存储(block device)。

一、现状
1、挂载点
node1 \
       ->  挂载  -> iscsi 块存储(block device)为： /dev/mapper/test_block_a
node2 /

2、在2个节点上创建一个目录用于后续挂载
# mkdir /mnt/t_lv01


二、操作
1、【node1】
1）使用 lvm 创建一个 pv, vg, lv
[root@node1 ~]# pvcreate /dev/mapper/test_block_a
[root@node1 ~]# vgcreate vg0 /dev/mapper/test_block_a
[root@node1 ~]# lvcreate -L 1G -n lv01 vg0
[root@node1 ~]# mkfs.ext4 /dev/vg0/lv01

2）查看 lvm 配置文件中保存的 vg 相关信息
[root@node1 ~]# cat /etc/lvm/backup/vg0
# Generated by LVM2 version 2.02.100(2)-RHEL6 (2013-10-23): Tue Nov 29 10:54:11 2016

contents = "Text Format Volume Group"
version = 1

description = "Created *after* executing 'lvcreate -L 1G -n lv01 vg0'"

creation_host = "node1.test.com"       # Linux node1.test.com 2.6.39-400.290.1.el6uek.x86_64 #1 SMP Mon Nov 7 12:59:33 PST 2016 x86_64
creation_time = 1480388051      # Tue Nov 29 10:54:11 2016

vg0 {
        id = "Yh4nLE-cEVh-dedi-pZRZ-S3PZ-w0dH-bSUqUf"
        seqno = 2
        format = "lvm2" # informational
        status = ["RESIZEABLE", "READ", "WRITE"]
        flags = []
        extent_size = 8192              # 4 Megabytes
        max_lv = 0
        max_pv = 0
        metadata_copies = 0

        physical_volumes {

                pv0 {
                        id = "m28MGI-3m4A-uhpN-EBVe-EYs6-3hCA-Tom1Px"
                        device = "/dev/mapper/test_block_a"     # Hint only

                        status = ["ALLOCATABLE"]
                        flags = []
                        dev_size = 209715200    # 100 Gigabytes
                        pe_start = 2048
                        pe_count = 25599        # 99.9961 Gigabytes
                }
        }

        logical_volumes {

                lv01 {
                        id = "mlJla3-t8cJ-hfva-te3Y-Jg7U-A9Fk-k6fvL6"
                        status = ["READ", "WRITE", "VISIBLE"]
                        flags = []
                        creation_host = "node1.test.com"
                        creation_time = 1480388051      # 2016-11-29 10:54:11 +0800
                        segment_count = 1

                        segment1 {
                                start_extent = 0
                                extent_count = 256      # 1024 Megabytes

                                type = "striped"
                                stripe_count = 1        # linear

                                stripes = [
                                        "pv0", 0
                                ]
                        }
                }
        }
}


3）查看 lv 的状态
[root@node1 ~]# lvdisplay 
  --- Logical volume ---
  LV Path                /dev/vg0/lv01
  LV Name                lv01
  VG Name                vg0
  LV UUID                mlJla3-t8cJ-hfva-te3Y-Jg7U-A9Fk-k6fvL6
  LV Write Access        read/write
  LV Creation host, time node1.test.com, 2016-11-29 10:54:11 +0800
  LV Status              available
  # open                 0
  LV Size                1.00 GiB
  Current LE             256
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     256
  Block device           251:1


划重点：  
  LV Status              available



2、【node2】
1）使用 vgs 获得当前操作的块存储(block device)上已经存在的 lvm 信息
[root@node2 ~]# vgs
  VG   #PV #LV #SN Attr   VSize   VFree 
  vg0    1   1   0 wz--n- 100.00g 99.00g
  
  
2）查看 lvm 配置文件中保存的 vg 相关信息
[root@node2 ~]# cat /etc/lvm/backup/vg0 
# Generated by LVM2 version 2.02.100(2)-RHEL6 (2013-10-23): Tue Nov 29 13:59:55 2016

contents = "Text Format Volume Group"
version = 1

description = "Created *after* executing 'vgs'"

creation_host = "node2.test.com"       # Linux node2.test.com 2.6.39-400.290.1.el6uek.x86_64 #1 SMP Mon Nov 7 12:59:33 PST 2016 x86_64
creation_time = 1480399195      # Tue Nov 29 13:59:55 2016

vg0 {
        id = "Yh4nLE-cEVh-dedi-pZRZ-S3PZ-w0dH-bSUqUf"
        seqno = 2
        format = "lvm2" # informational
        status = ["RESIZEABLE", "READ", "WRITE"]
        flags = []
        extent_size = 8192              # 4 Megabytes
        max_lv = 0
        max_pv = 0
        metadata_copies = 0

        physical_volumes {

                pv0 {
                        id = "m28MGI-3m4A-uhpN-EBVe-EYs6-3hCA-Tom1Px"
                        device = "/dev/mapper/test_block_a"     # Hint only

                        status = ["ALLOCATABLE"]
                        flags = []
                        dev_size = 209715200    # 100 Gigabytes
                        pe_start = 2048
                        pe_count = 25599        # 99.9961 Gigabytes
                }
        }

        logical_volumes {

                lv01 {
                        id = "mlJla3-t8cJ-hfva-te3Y-Jg7U-A9Fk-k6fvL6"
                        status = ["READ", "WRITE", "VISIBLE"]
                        flags = []
                        creation_host = "node1.test.com"
                        creation_time = 1480388051      # 2016-11-29 10:54:11 +0800
                        segment_count = 1

                        segment1 {
                                start_extent = 0
                                extent_count = 256      # 1024 Megabytes

                                type = "striped"
                                stripe_count = 1        # linear

                                stripes = [
                                        "pv0", 0
                                ]
                        }
                }
        }
}



3）查看 lv 的状态
[root@node2 ~]# lvdisplay 
  --- Logical volume ---
  LV Path                /dev/vg0/lv01
  LV Name                lv01
  VG Name                vg0
  LV UUID                mlJla3-t8cJ-hfva-te3Y-Jg7U-A9Fk-k6fvL6
  LV Write Access        read/write
  LV Creation host, time node1.test.com, 2016-11-29 10:54:11 +0800
  LV Status              NOT available
  LV Size                1.00 GiB
  Current LE             256
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
   
划重点：  
  LV Status              NOT available

  
3、小结
node1：使用 lvm 针对块存储(block device)分区，lv 可用
node2：使用 lvm 获取了块存储(block device)上的信息，但 lv 不可用


4、使用 lvchange 在node2上激活指定的 lv
[root@node2 ~]# ls /dev/vg0
ls: cannot access /dev/vg0: No such file or directory
[root@node2 ~]# lvchange -ay /dev/vg0/lv01
[root@node2 ~]# ls /dev/vg0               
lv01
[root@node2 ~]# lvdisplay                               
  --- Logical volume ---
  LV Path                /dev/vg0/lv01
  LV Name                lv01
  VG Name                vg0
  LV UUID                mlJla3-t8cJ-hfva-te3Y-Jg7U-A9Fk-k6fvL6
  LV Write Access        read/write
  LV Creation host, time node1.test.com, 2016-11-29 10:54:11 +0800
  LV Status              available
  # open                 0
  LV Size                1.00 GiB
  Current LE             256
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     256
  Block device           251:1

注意：这里存在一个问题，在2个节点都激活了这个 lv 后，如果同时读写了这个 lv，将导致什么后果？


5、如何取消激活
[root@node2 ~]# lvchange -an /dev/vg0/lv01
[root@node2 ~]# ls /dev/vg0               
ls: cannot access /dev/vg0: No such file or directory
[root@node2 ~]# lvdisplay                 
  --- Logical volume ---
  LV Path                /dev/vg0/lv01
  LV Name                lv01
  VG Name                vg0
  LV UUID                mlJla3-t8cJ-hfva-te3Y-Jg7U-A9Fk-k6fvL6
  LV Write Access        read/write
  LV Creation host, time node1.test.com, 2016-11-29 10:54:11 +0800
  LV Status              NOT available
  LV Size                1.00 GiB
  Current LE             256
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  
  
三、测试
1、用例1【仅在1哥节点上激活 lv，做读写操作】
1）在 node1 激活 lv 挂载并写入文件
[root@node1 ~]# echo [`date`] : `hostname` : [access] >>/mnt/t_lv01/1.log
[root@node1 ~]# cat /mnt/t_lv01/1.log 
[Tue Nov 29 14:24:04 CST 2016] : node1.test.com : [access]

2）在 node2 激活 lv 并且在 node1 取消激活该 lv，然后挂载并写入文件
激活
[root@node2 ~]# lvchange -ay /dev/vg0/lv01
[root@node2 ~]# lvdisplay |grep Status
  LV Status              available

取消激活
[root@node1 ~]# lvchange -an /dev/vg0/lv01
[root@node1 ~]# lvdisplay |grep Status
  LV Status              NOT available

挂载并写文件
[root@node2 ~]# mount /dev/vg0/lv01 /mnt/t_lv01/
[root@node2 ~]# cat /mnt/t_lv01/1.log 
[Tue Nov 29 14:24:04 CST 2016] : node1.test.com : [access]
[root@node2 ~]# echo [`date`] : `hostname` : [access] >>/mnt/t_lv01/1.log
[root@node2 ~]# cat /mnt/t_lv01/1.log                                    
[Tue Nov 29 14:24:04 CST 2016] : node1.test.com : [access]
[Tue Nov 29 14:26:29 CST 2016] : node2.test.com : [access]


2、用例2【同时在2个节点上激活 lv，一个写，一个读】
1）在 node1 激活 lv 挂载并写入文件
[root@node1 ~]# lvchange -ay /dev/vg0/lv01
[root@node1 ~]# mount /dev/vg0/lv01 /mnt/t_lv01/
[root@node1 ~]# cat /mnt/t_lv01/1.log 
[Tue Nov 29 14:24:04 CST 2016] : node1.test.com : [access]
[Tue Nov 29 14:26:29 CST 2016] : node2.test.com : [access]

结论：同时读，能正常获取数据。

2）在 node1 上写文件
[root@node1 ~]# for i in `seq 1 9`;do echo [`date`] : `hostname` : [access] : $i;done >>/mnt/t_lv01/1.log 
[root@node1 ~]# cat /mnt/t_lv01/1.log 
[Tue Nov 29 14:24:04 CST 2016] : node1.test.com : [access]
[Tue Nov 29 14:26:29 CST 2016] : node2.test.com : [access]
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 1
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 2
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 3
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 4
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 5
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 6
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 7
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 8
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 9

3）观察 node2 上查看到的文件内容
[root@node2 ~]# cat /mnt/t_lv01/1.log 
[Tue Nov 29 14:24:04 CST 2016] : node1.test.com : [access]
[Tue Nov 29 14:26:29 CST 2016] : node2.test.com : [access]

尴尬了，，没有显示更新的内容
重新挂载后再次查看：
[root@node2 ~]# umount /mnt/t_lv01/
[root@node2 ~]# mount /dev/vg0/lv01 /mnt/t_lv01/
[root@node2 ~]# cat /mnt/t_lv01/1.log           
[Tue Nov 29 14:24:04 CST 2016] : node1.test.com : [access]
[Tue Nov 29 14:26:29 CST 2016] : node2.test.com : [access]
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 1
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 2
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 3
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 4
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 5
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 6
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 7
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 8
[Tue Nov 29 14:33:21 CST 2016] : node1.test.com : [access] : 9

符合预期。


3、用例3【同时在2个节点上激活 lv，2个都读写】
[root@node1 ~]# for i in `seq 1 5`;do echo [`date`] : `hostname` : [access] : xxx$i >>/mnt/t_lv01/5.log;sleep 1s;done 
[root@node1 ~]# cat /mnt/t_lv01/5.log
[Tue Nov 29 15:02:08 CST 2016] : node1.test.com : [access] : xxx1
[Tue Nov 29 15:02:09 CST 2016] : node1.test.com : [access] : xxx2
[Tue Nov 29 15:02:10 CST 2016] : node1.test.com : [access] : xxx3
[Tue Nov 29 15:02:11 CST 2016] : node1.test.com : [access] : xxx4
[Tue Nov 29 15:02:12 CST 2016] : node1.test.com : [access] : xxx5
[root@node1 ~]# umount /mnt/t_lv01/ && mount /dev/vg0/lv01 /mnt/t_lv01/ && cat /mnt/t_lv01/5.log                     
[Tue Nov 29 15:02:08 CST 2016] : node2.test.com : [access] : yyy1
[Tue Nov 29 15:02:09 CST 2016] : node2.test.com : [access] : yyy2
[Tue Nov 29 15:02:10 CST 2016] : node2.test.com : [access] : yyy3
[Tue Nov 29 15:02:11 CST 2016] : node2.test.com : [access] : yyy4
[Tue Nov 29 15:02:12 CST 2016] : node2.test.com : [access] : yyy5

[root@node2 ~]# for i in `seq 1 5`;do echo [`date`] : `hostname` : [access] : yyy$i >>/mnt/t_lv01/5.log;sleep 1s;done    
[root@node2 ~]# cat /mnt/t_lv01/5.log
[Tue Nov 29 15:02:08 CST 2016] : node2.test.com : [access] : yyy1
[Tue Nov 29 15:02:09 CST 2016] : node2.test.com : [access] : yyy2
[Tue Nov 29 15:02:10 CST 2016] : node2.test.com : [access] : yyy3
[Tue Nov 29 15:02:11 CST 2016] : node2.test.com : [access] : yyy4
[Tue Nov 29 15:02:12 CST 2016] : node2.test.com : [access] : yyy5
[root@node2 ~]# umount /mnt/t_lv01/ && mount /dev/vg0/lv01 /mnt/t_lv01/ && cat /mnt/t_lv01/5.log
[Tue Nov 29 15:02:08 CST 2016] : node2.test.com : [access] : yyy1
[Tue Nov 29 15:02:09 CST 2016] : node2.test.com : [access] : yyy2
[Tue Nov 29 15:02:10 CST 2016] : node2.test.com : [access] : yyy3
[Tue Nov 29 15:02:11 CST 2016] : node2.test.com : [access] : yyy4
[Tue Nov 29 15:02:12 CST 2016] : node2.test.com : [access] : yyy5

数据已经错乱。


4、结论
lvm方式管理块存储(block device)时，如果同时激活同一个 lv 来做读写操作，将导致异常的结果。
建议通过管理平台做严格的访问限制。
 